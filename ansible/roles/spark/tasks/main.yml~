
- name: set spark distribution fact
  set_fact: spark_path=spark-{{ spark.version }}-bin-hadoop{{ spark.hadoop_version }}

- name: check spark downloaded
  command: test -f {{ spark.temp_dir }}/{{ spark_path }}.tgz
  delegate_to: localhost
  register: spark_downloaded
  failed_when: spark_downloaded.rc not in [0, 1]
  changed_when: false
  run_once: true

- name: download spark 
  command: get_url url="{{ spark.mirror }}/{{ spark_path }}.tgz" dest="{{ spark.temp_dir }}"
  delegate_to: localhost
  when: spark_downloaded.rc == 1
  run_once: true

- name: create group
  group:
    name: spark
    state: present

- name: create user
  user:
    name: spark
    group: spark

- name: create spark working directory
  file:
    path: "{{ spark.working_dir }}"
    state: directory
    owner: spark
    group: spark

- name: create install directory 
  file:
    path: "{{ spark.install_dir }}"
    state: directory
    owner: spark
    group: spark

- name: unarchive to the install directory
  unarchive:
    src: "{{ spark.temp_dir }}/{{ spark_path }}.tgz"
    dest: "{{ spark.install_dir }}"
    owner: spark
    group: spark
    creates: "{{ spark.install_dir }}/{{ spark_path }}/RELEASE"

- name: set spark-env.sh
  template: src="spark-env-sh.j2" dest="{{ spark.install_dir }}/{{ spark_path }}/conf/spark-env.sh"
  become: true

- name: set spark-defaults.conf
  template: src="spark-defaults-conf.j2" dest="{{ spark.install_dir}}/{{ spark_path }}/conf/spark-defaults.conf"

- name: copy master systemd start scripts
  template:
    src: "spark-master-systemd.j2"
    dest: /etc/systemd/system/spark-master.service
    owner: root
    group: root
  when: inventory_hostname in groups['spark-master'] 
  notify: 
    - restart spark-master

- name: copy worker systemd start scripts
  template:
    src: "spark-worker-systemd.j2"
    dest: /etc/systemd/system/spark-worker.service
    owner: root
    group: root
  when: inventory_hostname in groups['spark-workers'] 
  notify: 
    - restart spark-worker

- name: start spark masters
  service: name=spark-master state=started enabled=yes 
  when: inventory_hostname in groups['spark-masters']

- name: start spark workers
  service: name=spark-worker state=started enabled=yes 
  when: inventory_hostname in groups['spark-workers']
